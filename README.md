# Titanic_Survive

## Download dataset from Kaglle: https://www.kaggle.com/competitions/titanic

### Method used:

### Matplotlib Graphic plot(), Groupby(), info(), duplicated(), isnull(), describe() -> for Data Analysis

### get_dummies() -> for transform categorical variable to numeric

### seaborn.heatmap() -> for plot dataset correlation

### sklearn train_test_split -> to split the data into train and test

### train models "Logistic Regression": LogisticRegression(),
 ###         "KNN": KNeighborsClassifier(),
###          "Random Forest": RandomForestClassifier(),
###          "XGBoost": XGBClassifier(),
 ###         "CatBoost": CatBoostClassifier(),
###          "Gradient Boost Classifier": GradientBoostingClassifier(),
 ###         "Decision Tree Classifier": DecisionTreeClassifier(),
 ###         "KNClassifier": KNeighborsClassifier()

### sklearn MinMaxScaler -> to normalize the data

### confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score -> for evaluation metrics

### Accuracy GradientBoostingClassifier:  0.992822966507177
